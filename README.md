# assignment5-2
##设计思路
  分为两个mapreduce任务
  第一个任务的Mapper负责输出<单词，1>
  第一个任务的Reducer负责输出<单词，出现次数>
  第二个任务的Mapper负责输出<出现次数，单词>
  第二个任务的Reducer负责输出<"<排名>：<单词>，<次数>",Null>

##程序运⾏结果
1:s,76081
2:stocks,54702
3:q,48851
4:market,39551
5:eps,37997
6:vs,36796
7:m,36482
8:shares,36291
9:reports,33653
10:update,31535
11:est,30384
12:earnings,27821
13:benzinga,25589
14:week,23346
15:mid,21332
16:trading,20512
17:buy,20039
18:upgrades,19499
19:maintains,16435
20:downgrades,16098
21:higher,15627
22:day,15184
23:new,15072
24:session,15067
25:moving,14418
26:announces,13130
27:initiates,12050
28:b,11833
29:stock,11747
30:says,11746
31:companies,11384
32:coverage,11175
33:scheduled,11159
34:bank,11110
35:lower,10973
36:neutral,10675
37:energy,10607
38:biggest,10543
39:morgan,10211
40:sees,10075
41:company,10031
42:pre,9989
43:markets,9736
44:etfs,9717
45:capital,9711
46:morning,9701
47:yesterday,9595
48:watch,9587
49:movers,9381
50:sales,9347
51:share,9070
52:friday,8889
53:price,8591
54:fy,8555
55:group,8491
56:oil,8383
57:thursday,8019
58:following,7955
59:financial,7876
60:corporation,7760
61:adj,7617
62:results,7429
63:wednesday,7402
64:hit,7389
65:estimate,7363
66:outperform,7204
67:tuesday,7111
68:highs,6937
69:industry,6932
70:trade,6841
71:alert,6722
72:hold,6686
73:set,6669
74:option,6660
75:dividend,6629
76:analyst,6419
77:raises,6416
78:monday,6414
79:news,5986
80:lows,5851
81:sector,5833
82:rating,5787
83:etf,5629
84:year,5615
85:china,5561
86:revenue,5478
87:stanley,5427
88:highest,5376
89:global,5319
90:holdings,5300
91:high,5289
92:beats,5257
93:low,5146
94:overweight,5144
95:u,5108
96:services,5064
97:data,5025
98:gainers,4988
99:ahead,4784
100:deal,4784


##WEB⻚⾯截图
![image](https://github.com/user-attachments/assets/374da235-9cfa-4b0a-bcb7-1bc645355695)


##性能、扩展性等⽅⾯存在的不⾜和可能的改进之处
首先，一个很大的不足，是我规定了第二个任务的reducer数量为1，那如果数据规模增大，单个reducer的工作量将会太大。由于不支持多个reducer的并行处理，在大规模数据下性能将会明显下降。而我之所以将reducer数量设为1的原因，是我不知道如果有多个reducer，该如何计算排名，我知道可以用TotalOrderPartitioner进行partition，保证每个reducer得到的词频是全局排好序的，可是写在前面的这个ranking值怎么计算呢，我没想明白。
另外还有一个很大的不足，是我没有用第二个任务的mapper先得到每个mapper内部的前100，再由多个mapper汇总，在reducer中得到前100.之所以没有这样做的原因，是因为我偷懒了
